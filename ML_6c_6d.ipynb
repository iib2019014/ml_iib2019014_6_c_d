{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"ML_6c_6d.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMZHmcxdEw26uzAoajBM0c2"},"kernelspec":{"name":"python3","display_name":"Python 3.9.5 64-bit"},"language_info":{"name":"python","version":"3.9.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"c04a1cfadbcc7f8a0f5204fb1a2bf5fa0125856e3928479706b9f7565b2f6d7c"}},"cells":[{"cell_type":"code","execution_count":2,"source":["import pandas as pd\r\n","import sys"],"outputs":[],"metadata":{"id":"MgKeSicU2Zsl","executionInfo":{"status":"ok","timestamp":1631811043216,"user_tz":-330,"elapsed":342,"user":{"displayName":"Manvith Yadav Dega","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv7eT6UinE_h4U4SKYfcOG5LyHWriphE39S0BT=s64","userId":"16770744843720513719"}}}},{"cell_type":"code","execution_count":3,"source":["# below code is for getting the train data (70% of dataset) from github,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["train_len = 382\r\n","columns = ['price', 'lotsize', 'bedrooms', 'bathrms']\r\n","traindata = pd.read_csv('https://raw.githubusercontent.com/iib2019014/ml_iib2019014_datasets/main/Housing%20Price%20data%20set.csv', nrows=train_len, usecols=columns)\r\n","# traindata.to_csv('traindata.csv')\r\n","\r\n","testdata = pd.read_csv('https://raw.githubusercontent.com/iib2019014/ml_iib2019014_datasets/main/Housing%20Price%20data%20set.csv', skiprows=[i for i in range(1, train_len)], usecols=columns)\r\n","# testdata.to_csv('testdata.csv')\r\n","\r\n","# %ls \"\""],"outputs":[],"metadata":{"id":"eo6GB_bZ1g3S","executionInfo":{"status":"ok","timestamp":1631811046356,"user_tz":-330,"elapsed":324,"user":{"displayName":"Manvith Yadav Dega","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv7eT6UinE_h4U4SKYfcOG5LyHWriphE39S0BT=s64","userId":"16770744843720513719"}}}},{"cell_type":"code","execution_count":5,"source":["# below code is for individually storing the features and price,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["y, x1, x2, x3 = [], [], [], []\r\n","\r\n","for i in range(train_len) :\r\n","  y.append(traindata['price'][i])\r\n","  x1.append(traindata['lotsize'][i])\r\n","  x2.append(traindata['bedrooms'][i])\r\n","  x3.append(traindata['bathrms'][i])"],"outputs":[],"metadata":{"id":"BLh_0ooZ2ogi","executionInfo":{"status":"ok","timestamp":1631811048894,"user_tz":-330,"elapsed":5,"user":{"displayName":"Manvith Yadav Dega","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv7eT6UinE_h4U4SKYfcOG5LyHWriphE39S0BT=s64","userId":"16770744843720513719"}}}},{"cell_type":"markdown","source":["partialDerivate(W, wrt) function calculates the partial derivative of the error function with respective to the parameter w[wrt], where 'wrt' is the index in parameter list, W.\n","\n","getError(W) function calculates the error with respective to the corresponding parameters list, W."],"metadata":{"id":"hhf39VMU8Zol"}},{"cell_type":"markdown","source":["Gradient Descent Algorithm"],"metadata":{"id":"3sIjOV_UQ6ym"}},{"cell_type":"code","execution_count":7,"source":["# below cell has the functions to calculate the partial derivative and error,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["def partialDerivate(w0, w1, w2, w3, wrt) :\r\n","  derivative_at = 0\r\n","  if wrt == 0 :\r\n","    derivative_at = 0\r\n","    for i in range(m) :\r\n","      derivative_at += w0 + w1 * x1[i] + w2 * x2[i] + w3 * x3[i] - y[i]\r\n","    derivative_at /= m\r\n","    \r\n","  if wrt == 1 :\r\n","    derivative_at = 0\r\n","    for i in range(m) :\r\n","      derivative_at += (w0 + w1 * x1[i] + w2 * x2[i] + w3 * x3[i] - y[i]) * x1[i]\r\n","    derivative_at /= m\r\n","\r\n","  if wrt == 2 :\r\n","    derivative_at = 0\r\n","    for i in range(m) :\r\n","      derivative_at += (w0 + w1 * x1[i] + w2 * x2[i] + w3 * x3[i] - y[i]) * x2[i]\r\n","    derivative_at /= m\r\n","\r\n","  if wrt == 3 :\r\n","    derivative_at = 0\r\n","    for i in range(m) :\r\n","      derivative_at += (w0 + w1 * x1[i] + w2 * x2[i] + w3 * x3[i] - y[i]) * x3[i]\r\n","    derivative_at /= m\r\n","\r\n","  return derivative_at\r\n","\r\n","\r\n","def getError(w0, w1, w2, w3) :\r\n","  error = 0\r\n","  for i in range(m) :\r\n","    error += (w0 + w1 * x1[i] + w2 * x2[i] + w3 * x3[i] - y[i]) ** 2\r\n","\r\n","  return error / (2 * m)"],"outputs":[],"metadata":{"id":"d7NjXMQb4Xbf","executionInfo":{"status":"ok","timestamp":1631811050337,"user_tz":-330,"elapsed":6,"user":{"displayName":"Manvith Yadav Dega","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv7eT6UinE_h4U4SKYfcOG5LyHWriphE39S0BT=s64","userId":"16770744843720513719"}}}},{"cell_type":"markdown","source":["In the below cell, code for Batch-Gradient Descent Algo is writtem.\n","We expect the convergence will happend after 100 iterations.\n","Learning rate is taken to be 0.5"],"metadata":{"id":"cWq69fnj86tP"}},{"cell_type":"code","execution_count":9,"source":["converge_limit = 45\r\n","learning_rate = 0.00000001\r\n","minerror = sys.maxsize\r\n","m = train_len\r\n","# w0, w1, w2, w3 = 0, 0, 0, 0\r\n","w0, w1, w2, w3 = 1, 1, 1, 1\r\n","b0, b1, b2, b3 = 0, 0, 0, 0\r\n","\r\n","\r\n","for i in range(converge_limit) :\r\n","  pd = partialDerivate(w0, w1, w2, w3, 0)\r\n","  t0 = w0 - learning_rate * pd\r\n","  # w0 = w0 - learning_rate * pd\r\n","  pd = partialDerivate(w0, w1, w2, w3, 1)\r\n","  t1 = w1 - learning_rate * pd\r\n","  # w1 = w1 - learning_rate * pd\r\n","  pd = partialDerivate(w0, w1, w2, w3, 2)\r\n","  t2 = w2 - learning_rate * pd\r\n","  # w2 = w2 - learning_rate * pd\r\n","  pd = partialDerivate(w0, w1, w2, w3, 2)\r\n","  t3 = w3 - learning_rate * pd\r\n","  # w3 = w3 - learning_rate * pd\r\n","  w0, w1, w2, w3 = t0, t1, t2, t3\r\n","  error = getError(w0, w1, w2, w3)\r\n","  if error < minerror :\r\n","    minerror = error\r\n","    b0, b1, b2, b3 = w0, w1, w2, w3\r\n","\r\n","print(\"Minimum error is: \" + str(minerror))\r\n","print(\"Corresponding parameters are: \")\r\n","print(b0, b1, b2, b3)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Minimum error is: 317496785.9328654\n","Corresponding parameters are: \n","1.0039662991439684 12.513264188138088 1.0137825768806674 1.0137825768806674\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MbpNXT4m3G3c","executionInfo":{"status":"ok","timestamp":1631811052693,"user_tz":-330,"elapsed":353,"user":{"displayName":"Manvith Yadav Dega","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv7eT6UinE_h4U4SKYfcOG5LyHWriphE39S0BT=s64","userId":"16770744843720513719"}},"outputId":"714fe544-cf38-4076-80fd-0b28261ffc5b"}},{"cell_type":"markdown","source":["# Analysis of error estimation using different learning rates\r\n","\r\n","for learning rate = 0.00000001</br>\r\n","Minimum error is: 317527390.37990797</br>\r\n","Corresponding parameters are: \r\n","0.006492306262885747, 12.514213155262858, 0.023658411497197745, 0.023658411497197745\r\n","\r\n","for learning rate = 0.000000001</br>\r\n","Minimum error is: 326643185.95875156\r\n","Corresponding parameters are: \r\n","0.002503928553911345 11.689990520090188 0.007933867079084573 0.007933867079084573\r\n","\r\n","for learning rate = 0.0000001</br>\r\n","Minimum error is: 6272882965.908103</br>\r\n","Corresponding parameters are: \r\n","0.006393635340314135, 33.58195581151832, 0.019611233246073296, 0.019611233246073296\r\n","\r\n","for learning rate = 0.000001</br>\r\n","Minimum error is: 1402801609354.605\r\n","Corresponding parameters are: \r\n","0.06393635340314135 335.8195581151832 0.19611233246073298 0.19611233246073298"],"metadata":{"id":"vtirnNccDpw0"}},{"cell_type":"code","execution_count":10,"source":["# below cell calculates the error with batch gradient descent,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["error = 0\r\n","for i in range(len(testdata)) :\r\n","    error += (testdata['price'][i] - (b0 + b1 * testdata['lotsize'][i] + b2 * testdata['bedrooms'][i] + b3 * testdata['bathrms'][i])) ** 2\r\n","\r\n","print(\"error is \" + str(error / (2 * len(testdata))))"],"outputs":[{"output_type":"stream","name":"stdout","text":["error is 401132617.9874337\n"]}],"metadata":{}},{"cell_type":"markdown","source":["Stochastic Gradient Descent Algorithm"],"metadata":{"id":"XJ2ceD4PQzvm"}},{"cell_type":"code","execution_count":12,"source":["converge_limit = 100\r\n","learning_rate = 0.00001\r\n","minerror = sys.maxsize\r\n","m = train_len\r\n","w0, w1, w2, w3 = 0, 0, 0, 0\r\n","b0, b1, b2, b3 = 0, 0, 0, 0\r\n","\r\n","for i in range(converge_limit) :\r\n","  k = i * m // converge_limit\r\n","  t0 = w0 - learning_rate * (w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) / m\r\n","  t1 = w1 - learning_rate * ((w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x1[k]) / m\r\n","  t2 = w2 - learning_rate * ((w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x2[k]) / m\r\n","  t3 = w3 - learning_rate * ((w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x3[k]) / m\r\n","\r\n","  w0, w1, w2, w3 = t0, t1, t2, t3\r\n","  error = getError(w0, w1, w2, w3)\r\n","  if error < minerror :\r\n","    minerror = error\r\n","    b0, b1, b2, b3 = w0, w1, w2, w3\r\n","\r\n","print(learning_rate)\r\n","print(\"Minimum error is: \" + str(minerror))\r\n","print(\"Corresponding parameters are: \")\r\n","print(b0, b1, b2, b3)"],"outputs":[{"output_type":"stream","name":"stdout","text":["1e-05\n","Minimum error is: 317904561.91707104\n","Corresponding parameters are: \n","0.007779951407274272 12.346619589370821 0.01652198301032323 0.00715471214079526\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XyrJ2KY679XZ","executionInfo":{"status":"ok","timestamp":1631811294080,"user_tz":-330,"elapsed":323,"user":{"displayName":"Manvith Yadav Dega","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv7eT6UinE_h4U4SKYfcOG5LyHWriphE39S0BT=s64","userId":"16770744843720513719"}},"outputId":"187c29ce-f66d-48de-ed37-4fcded9c8bc6"}},{"cell_type":"markdown","source":["# Analysis of error estimation using different learning rates\r\n","\r\n","for learning rate = 0.0001</br>\r\n","Minimum error is: 36327090871.993645</br>\r\n","Corresponding parameters are: \r\n","0.01099476439790576, 64.31937172774869, 0.03298429319371728, 0.01099476439790576\r\n","\r\n","for learning rate = 0.00001</br>\r\n","Minimum error is: 317904561.91707104</br>\r\n","Corresponding parameters are: \r\n","0.007779951407274272, 12.346619589370821, 0.01652198301032323, 0.00715471214079526\r\n","\r\n","for learning rate = 0.000001</br>\r\n","Minimum error is: 317527896.40058625</br>\r\n","Corresponding parameters are: \r\n","0.003399376904692982, 12.516202404263344, 0.00892773354359082, 0.0039020307829233025\r\n","\r\n","for learning rate = 0.0000001</br>\r\n","Minimum error is: 1092576692.2315826</br>\r\n","Corresponding parameters are: \r\n","0.0010938203180438553, 4.913967141761904, 0.003047065368094102, 0.001325219280389634"],"metadata":{"id":"Lezk__M7F6c0"}},{"cell_type":"code","execution_count":13,"source":["# below cell calculates the error with stochastic gradient descent,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["error = 0\r\n","for i in range(len(testdata)) :\r\n","    error += (testdata['price'][i] - (b0 + b1 * testdata['lotsize'][i] + b2 * testdata['bedrooms'][i] + b3 * testdata['bathrms'][i])) ** 2\r\n","\r\n","print(\"error is \" + str(error / (2 * len(testdata))))"],"outputs":[{"output_type":"stream","name":"stdout","text":["error is 397054274.24884486\n"]}],"metadata":{}},{"cell_type":"markdown","source":["Mini-Batch Gradient Descent Algorithm"],"metadata":{"id":"qkvVUDe3QpDh"}},{"cell_type":"code","execution_count":44,"source":["converge_limit = 100\r\n","learning_rate = 0.00001\r\n","minerror = sys.maxsize\r\n","m = train_len\r\n","w0, w1, w2, w3 = 0, 0, 0, 0\r\n","b0, b1, b2, b3 = 0, 0, 0, 0\r\n","\r\n","for i in range(converge_limit) :\r\n","  j = i * m // converge_limit\r\n","  sum0, sum1, sum2, sum3 = 0, 0, 0, 0\r\n","  for k in range(10) :\r\n","    if j + k >= train_len :\r\n","      break\r\n","    sum0 += w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]\r\n","    sum1 += (w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x1[k]\r\n","    sum2 += (w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x2[k]\r\n","    sum3 += (w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x3[k]\r\n","  t0 = w0 - learning_rate * sum0 / m\r\n","  t1 = w1 - learning_rate * sum2 / m\r\n","  t2 = w2 - learning_rate * sum2 / m\r\n","  t3 = w3 - learning_rate * sum3 / m\r\n","\r\n","  w0, w1, w2, w3 = t0, t1, t2, t3\r\n","  error = getError(w0, w1, w2, w3)\r\n","  if error < minerror :\r\n","    minerror = error\r\n","    b0, b1, b2, b3 = w0, w1, w2, w3\r\n","\r\n","print(learning_rate)\r\n","print(\"Minimum error is: \" + str(minerror))\r\n","print(\"Corresponding parameters are: \")\r\n","print(b0, b1, b2, b3)"],"outputs":[{"output_type":"stream","name":"stdout","text":["1e-05\n","Minimum error is: 1443701447.1143599\n","Corresponding parameters are: \n","1.1955455496463587 3.350081055970454 3.350081055970454 1.4351759732254343\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VHdYfN2m8Wo6","executionInfo":{"status":"ok","timestamp":1631811276122,"user_tz":-330,"elapsed":338,"user":{"displayName":"Manvith Yadav Dega","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv7eT6UinE_h4U4SKYfcOG5LyHWriphE39S0BT=s64","userId":"16770744843720513719"}},"outputId":"7602cf21-e4f9-4ff1-e374-02f699e45eae"}},{"cell_type":"markdown","source":["# Analysis of error estimation using different learning rates\r\n","\r\n","for learning rate = 0.01</br>\r\n","Minimum error is: 4806592020.676374</br>\r\n","Corresponding parameters are: \r\n","10.99476439790576, 30.785340314136125, 30.785340314136125, 13.193717277486911\r\n","\r\n","for learning rate = 0.001</br>\r\n","Minimum error is: 317251564.95131403</br>\r\n","Corresponding parameters are: \r\n","4.012063537369557, 12.487660475302741, 12.487660475302741, 5.3778116726440155\r\n","\r\n","for learning rate = 0.0001</br>\r\n","Minimum error is: 319943740.2773181</br>\r\n","Corresponding parameters are: \r\n","4.260235075117864, 12.058207614163068, 12.058207614163068, 5.170485407624245\r\n","\r\n","for learning rate = 1e-05</br>\r\n","Minimum error is: 1443701447.1143599</br>\r\n","Corresponding parameters are: \r\n","1.1955455496463587 3.350081055970454 3.350081055970454 1.4351759732254343"],"metadata":{"id":"Zgxg0OJhTU8D"}},{"cell_type":"code","execution_count":16,"source":["# below cell calculates the error with mini-batch gradient descent,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":17,"source":["error = 0\r\n","for i in range(len(testdata)) :\r\n","    error += (testdata['price'][i] - (b0 + b1 * testdata['lotsize'][i] + b2 * testdata['bedrooms'][i] + b3 * testdata['bathrms'][i])) ** 2\r\n","\r\n","print(\"error is \" + str(error / (2 * len(testdata))))"],"outputs":[{"output_type":"stream","name":"stdout","text":["error is 1882824970.8933487\n"]}],"metadata":{}},{"cell_type":"markdown","source":["# With Regularization"],"metadata":{"id":"KvZIp8NTKNEb"}},{"cell_type":"code","execution_count":18,"source":["# below cell has the functions for calculating the partial derivates and error, but here along with regularization term,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":19,"source":["def partialDerivateReg(w0, w1, w2, w3, wrt, hyplambda) :\r\n","  derivative_at = 0\r\n","  if wrt == 0 :\r\n","    derivative_at = 0\r\n","    for i in range(m) :\r\n","      derivative_at += w0 + w1 * x1[i] + w2 * x2[i] + w3 * x3[i] - y[i] + (hyplambda * w0)\r\n","    derivative_at /= m\r\n","    \r\n","  if wrt == 1 :\r\n","    derivative_at = 0\r\n","    for i in range(m) :\r\n","      derivative_at += (w0 + w1 * x1[i] + w2 * x2[i] + w3 * x3[i] - y[i]) * x1[i] + (hyplambda * w1)\r\n","    derivative_at /= m\r\n","\r\n","  if wrt == 2 :\r\n","    derivative_at = 0\r\n","    for i in range(m) :\r\n","      derivative_at += (w0 + w1 * x1[i] + w2 * x2[i] + w3 * x3[i] - y[i]) * x2[i] + (hyplambda * w2)\r\n","    derivative_at /= m\r\n","\r\n","  if wrt == 3 :\r\n","    derivative_at = 0\r\n","    for i in range(m) :\r\n","      derivative_at += (w0 + w1 * x1[i] + w2 * x2[i] + w3 * x3[i] - y[i]) * x3[i] + (hyplambda * w3)\r\n","    derivative_at /= m\r\n","\r\n","  return derivative_at\r\n","\r\n","\r\n","def getErrorReg(w0, w1, w2, w3, hyplambda) :\r\n","  error = 0\r\n","  for i in range(m) :\r\n","    error += (w0 + w1 * x1[i] + w2 * x2[i] + w3 * x3[i] - y[i]) ** 2\r\n","\r\n","  error +=  hyplambda * (w0 ** 2 + w1 ** 2 + w2 ** 2 + w3 ** 2)\r\n","\r\n","  return error / (2 * m)"],"outputs":[],"metadata":{"id":"_CYV3IxXKSfM","executionInfo":{"status":"ok","timestamp":1631811327426,"user_tz":-330,"elapsed":328,"user":{"displayName":"Manvith Yadav Dega","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv7eT6UinE_h4U4SKYfcOG5LyHWriphE39S0BT=s64","userId":"16770744843720513719"}}}},{"cell_type":"markdown","source":["Batch-Gradient Descent Algorithm"],"metadata":{}},{"cell_type":"code","execution_count":45,"source":["converge_limit = 100\r\n","learning_rate = 0.0000001\r\n","minerror = sys.maxsize\r\n","m = train_len\r\n","w0, w1, w2, w3 = 0, 0, 0, 0\r\n","b0, b1, b2, b3 = 0, 0, 0, 0\r\n","hyplambda = 0.0005\r\n","\r\n","\r\n","for i in range(converge_limit) :\r\n","  pd = partialDerivateReg(w0, w1, w2, w3, 0, hyplambda)\r\n","  t0 = w0 - learning_rate * pd\r\n","  pd = partialDerivateReg(w0, w1, w2, w3, 1, hyplambda)\r\n","  t1 = w1 - learning_rate * pd\r\n","  pd = partialDerivateReg(w0, w1, w2, w3, 2, hyplambda)\r\n","  t2 = w2 - learning_rate * pd\r\n","  pd = partialDerivateReg(w0, w1, w2, w3, 2, hyplambda)\r\n","  t3 = w3 - learning_rate * pd\r\n","  w0, w1, w2, w3 = t0, t1, t2, t3\r\n","  error = getErrorReg(w0, w1, w2, w3, hyplambda)\r\n","  if error < minerror :\r\n","    minerror = error\r\n","    b0, b1, b2, b3 = w0, w1, w2, w3\r\n","\r\n","print(\"Minimum error is: \" + str(minerror))\r\n","print(\"Corresponding parameters are: \")\r\n","print(b0, b1, b2, b3)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Minimum error is: 6272882965.908841\n","Corresponding parameters are: \n","0.006393635340314135 33.58195581151832 0.019611233246073296 0.019611233246073296\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKwT0amALIF3","executionInfo":{"status":"ok","timestamp":1631811335446,"user_tz":-330,"elapsed":923,"user":{"displayName":"Manvith Yadav Dega","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv7eT6UinE_h4U4SKYfcOG5LyHWriphE39S0BT=s64","userId":"16770744843720513719"}},"outputId":"6df6ff13-ade3-4811-c38c-1f30a7a111b1"}},{"cell_type":"markdown","source":["lambda = 0.0005</br>\r\n","Minimum error is: 317527390.38001066</br>\r\n","Corresponding parameters are: \r\n","0.006492306261787789, 12.514213155029692, 0.023658411492870034, 0.023658411492870034\r\n","\r\n","lambda = 0.5</br>\r\n","Minimum error is: 317527390.4825164</br>\r\n","Corresponding parameters are: \r\n","0.006492305164926526, 12.514212922096618, 0.023658407169479923, 0.023658407169479923\r\n","\r\n","lambda = 1.5</br>\r\n","Minimum error is: 317527390.6877382</br>\r\n","Corresponding parameters are: \r\n","0.006492302969009118, 12.514212455764167, 0.0236583985140484, 0.0236583985140484"],"metadata":{"id":"m7w7baqIL5s2"}},{"cell_type":"code","execution_count":21,"source":["# below cell calculates the error with batch gradient descent using regularization,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":22,"source":["error = 0\r\n","for i in range(len(testdata)) :\r\n","    error += (testdata['price'][i] - (b0 + b1 * testdata['lotsize'][i] + b2 * testdata['bedrooms'][i] + b3 * testdata['bathrms'][i])) ** 2\r\n","\r\n","print(\"error is \" + str(error / (2 * len(testdata))))"],"outputs":[{"output_type":"stream","name":"stdout","text":["error is 401180244.65862715\n"]}],"metadata":{}},{"cell_type":"markdown","source":["Stochastic Gradient Descent Algorithm"],"metadata":{}},{"cell_type":"code","execution_count":51,"source":["converge_limit = 100\r\n","learning_rate = 0.000001\r\n","minerror = sys.maxsize\r\n","m = train_len\r\n","w0, w1, w2, w3 = 0, 0, 0, 0\r\n","b0, b1, b2, b3 = 0, 0, 0, 0\r\n","hyplambda = 0.005\r\n","\r\n","for i in range(converge_limit) :\r\n","  k = i * m // converge_limit\r\n","  t0 = w0 - learning_rate * 1/m * ((w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) + (hyplambda * w0))\r\n","  t1 = w1 - learning_rate * 1/m * (((w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x1[k]) + (hyplambda * w1))\r\n","  t2 = w2 - learning_rate * 1/m * (((w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x2[k]) + (hyplambda * w2))\r\n","  t3 = w3 - learning_rate * 1/m * (((w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x3[k]) + (hyplambda * w3))\r\n","\r\n","  w0, w1, w2, w3 = t0, t1, t2, t3\r\n","  error = getError(w0, w1, w2, w3)\r\n","  if error < minerror :\r\n","    minerror = error\r\n","    b0, b1, b2, b3 = w0, w1, w2, w3\r\n","\r\n","print(learning_rate)\r\n","print(\"Minimum error is: \" + str(minerror))\r\n","print(\"Corresponding parameters are: \")\r\n","print(b0, b1, b2, b3)"],"outputs":[{"output_type":"stream","name":"stdout","text":["1e-06\n","Minimum error is: 317527896.4004116\n","Corresponding parameters are: \n","0.003399376903808568 12.516202400974228 0.008927733541568457 0.0039020307820025117\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O9TbQG35ifDL","executionInfo":{"status":"ok","timestamp":1631811808321,"user_tz":-330,"elapsed":331,"user":{"displayName":"Manvith Yadav Dega","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv7eT6UinE_h4U4SKYfcOG5LyHWriphE39S0BT=s64","userId":"16770744843720513719"}},"outputId":"da1c165b-b241-4f9f-9983-e35d130050d3"}},{"cell_type":"markdown","source":["for learning rate = 1e-05</br>\r\n","Minimum error is: 317904561.92808753</br>\r\n","Corresponding parameters are: \r\n","0.007779951395284366 12.346619586921399 0.016521982991642467 0.007154712133347393\r\n","\r\n","for learning rate = 1e-06</br>\r\n","Minimum error is: 317527896.4004116</br>\r\n","Corresponding parameters are: \r\n","0.003399376903808568 12.516202400974228 0.008927733541568457 0.0039020307820025117\r\n","\r\n","for learning rate = 1e-07</br>\r\n","Minimum error is: 1092576692.2807183</br>\r\n","Corresponding parameters are: \r\n","0.0010938203179799088 4.91396714152099 0.0030470653679212675 0.001325219280312025\r\n","\r\n","for learning rate = 1e-08</br>\r\n","Minimum error is: 2203959170.177111</br>\r\n","Corresponding parameters are: \r\n","0.00013793070332628532 0.6569651734812031 0.0003882756382303034 0.00017021293909980282"],"metadata":{"id":"U9plq4jUjIBe"}},{"cell_type":"code","execution_count":24,"source":["# below cell calculates the error with stochastic gradient descent using regularization,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":25,"source":["error = 0\r\n","for i in range(len(testdata)) :\r\n","    error += (testdata['price'][i] - (b0 + b1 * testdata['lotsize'][i] + b2 * testdata['bedrooms'][i] + b3 * testdata['bathrms'][i])) ** 2\r\n","\r\n","print(\"error is \" + str(error / (2 * len(testdata))))"],"outputs":[{"output_type":"stream","name":"stdout","text":["error is 2980821982.2258143\n"]}],"metadata":{}},{"cell_type":"markdown","source":["Mini-Batch Gradient Descent Algorithm"],"metadata":{}},{"cell_type":"code","execution_count":26,"source":["converge_limit = 100\r\n","learning_rate = 0.001\r\n","minerror = sys.maxsize\r\n","m = train_len\r\n","w0, w1, w2, w3 = 0, 0, 0, 0\r\n","b0, b1, b2, b3 = 0, 0, 0, 0\r\n","\r\n","for i in range(converge_limit) :\r\n","  j = i * m // converge_limit\r\n","  sum0, sum1, sum2, sum3 = 0, 0, 0, 0\r\n","  for k in range(10) :\r\n","    if j + k >= train_len :\r\n","      break\r\n","    sum0 += ((w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) + (hyplambda * w0))\r\n","    sum1 += (((w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x1[k]) + (hyplambda * w1))\r\n","    sum2 += (((w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x2[k]) + (hyplambda * w2))\r\n","    sum3 += (((w0 + w1 * x1[k] + w2 * x2[k] + w3 * x3[k] - y[i]) * x3[k]) + (hyplambda * w3))\r\n","  t0 = w0 - learning_rate * sum0 / m\r\n","  t1 = w1 - learning_rate * sum2 / m\r\n","  t2 = w2 - learning_rate * sum2 / m\r\n","  t3 = w3 - learning_rate * sum3 / m\r\n","\r\n","  w0, w1, w2, w3 = t0, t1, t2, t3\r\n","  error = getError(w0, w1, w2, w3)\r\n","  if error < minerror :\r\n","    minerror = error\r\n","    b0, b1, b2, b3 = w0, w1, w2, w3\r\n","\r\n","print(learning_rate)\r\n","print(\"Minimum error is: \" + str(minerror))\r\n","print(\"Corresponding parameters are: \")\r\n","print(b0, b1, b2, b3)"],"outputs":[{"output_type":"stream","name":"stdout","text":["0.001\n","Minimum error is: 317251566.9762469\n","Corresponding parameters are: \n","4.012064149425027 12.487656441938277 12.487656441938277 5.377809825089577\n"]}],"metadata":{}},{"cell_type":"markdown","source":["0.001\r\n","Minimum error is: 317251566.9762469\r\n","Corresponding parameters are: \r\n","4.012064149425027 12.487656441938277 12.487656441938277 5.377809825089577\r\n","\r\n","0.0001\r\n","Minimum error is: 319943781.2928109\r\n","Corresponding parameters are: \r\n","4.260233892792104 12.058204208300243 12.058204208300243 5.1704839459946434\r\n","\r\n","1e-05\r\n","Minimum error is: 1443701495.4302328\r\n","Corresponding parameters are: \r\n","1.195545479608556 3.3500808596056912 3.3500808596056912 1.4351758890314188\r\n","\r\n","1e-06\r\n","Minimum error is: 2290456823.9002075\r\n","Corresponding parameters are: \r\n","0.13853420698045682 0.3878714655534293 0.3878714655534293 0.1661181362496273"],"metadata":{}},{"cell_type":"code","execution_count":27,"source":["# below cell calculates the error with mini-batch gradient descent using regularization,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":28,"source":["error = 0\r\n","for i in range(len(testdata)) :\r\n","    error += (testdata['price'][i] - (b0 + b1 * testdata['lotsize'][i] + b2 * testdata['bedrooms'][i] + b3 * testdata['bathrms'][i])) ** 2\r\n","    \r\n","print(\"error is \" + str(error / (2 * len(testdata))))"],"outputs":[{"output_type":"stream","name":"stdout","text":["error is 400253671.9536608\n"]}],"metadata":{}},{"cell_type":"markdown","source":["# QUESTION 6d"],"metadata":{"id":"BYgayBJvYA0g"}},{"cell_type":"code","execution_count":29,"source":["# beow cell has imports of numpy and math to solve the matrix operations and exponential funciton,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":30,"source":["import numpy as np\r\n","import math"],"outputs":[],"metadata":{"id":"a5aDhCPKYGOm","executionInfo":{"status":"ok","timestamp":1631807805420,"user_tz":-330,"elapsed":5,"user":{"displayName":"Manvith Yadav Dega","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv7eT6UinE_h4U4SKYfcOG5LyHWriphE39S0BT=s64","userId":"16770744843720513719"}}}},{"cell_type":"code","execution_count":31,"source":["# below function calculates the weight for each sample point from the query point,\r\n","# test1, test2, test3 are the features of the query point,\r\n","# train1, train2, train3 are the features of the sample point,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":32,"source":["def calcWeight(test1, test2, test3, train1, train2, train3, tau) :\r\n","    distanceSquare = (test1 - train1) ** 2 + (test2 - train2) ** 2 + (test3 - train3) ** 2\r\n","    e = math.exp(-(distanceSquare/(2 * tau ** 2)))\r\n","    return e"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":33,"source":["# below cell calculates the optimal parameters using the locally weighted regression technique,\r\n","# different tau values are selected,"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":41,"source":["X = [[1 for i in range(train_len)], x1, x2, x3]\r\n","weights = [[0 for i in range(train_len)] for j in range(train_len)]\r\n","tau = 310\r\n","error = 0\r\n","\r\n","for i in range(len(testdata)) :\r\n","    for j in range(train_len) :\r\n","        weights[j][j] = calcWeight(testdata['lotsize'][i], testdata['bedrooms'][i], testdata['bathrms'][i], traindata['lotsize'][j], traindata['bedrooms'][j], traindata['bathrms'][j], tau)\r\n","    w = np.dot(np.linalg.inv(np.dot(np.dot(X, weights), np.transpose(X))), (np.dot(np.dot(X, weights), y)))\r\n","    error += (testdata['price'][i] - (w[0] + w[1] * testdata['lotsize'][i] + w[2] * testdata['bedrooms'][i] + w[3] * testdata['bathrms'][i])) ** 2\r\n","error\r\n","\r\n","print(w)\r\n","# print(error)\r\n","print(error / (2 * len(testdata)))"],"outputs":[{"output_type":"stream","name":"stdout","text":["[-6.34104742e+04  1.34586300e+01  9.22778922e+03  2.33104689e+04]\n","174319420.69389585\n"]}],"metadata":{}},{"cell_type":"markdown","source":["tau = 290</br>\r\n","[-6.14719383e+04  1.30014834e+01  9.65695268e+03  2.30397487e+04]</br>\r\n","309769532.58574605\r\n","\r\n","tau = 295</br>\r\n","[-6.20593384e+04  1.31343009e+01  9.54468663e+03  2.31119248e+04]</br>\r\n","178153536.31572813</br>\r\n","\r\n","tau = 300</br>\r\n","[-6.25767508e+04  1.32545159e+01  9.43575495e+03  2.31810297e+04]</br>\r\n","162797522.4925398</br>\r\n","\r\n","tau = 305</br>\r\n","[-6.30263680e+04  1.33624965e+01  9.33013372e+03  2.32471749e+04]</br>\r\n","276294199.9975849</br>\r\n","\r\n","tau = 310</br>\r\n","[-6.34104742e+04  1.34586300e+01  9.22778922e+03  2.33104689e+04]</br>\r\n","174319420.69389585</br>"],"metadata":{}}]}